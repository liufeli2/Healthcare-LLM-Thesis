{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1GSnd9JWzxGnPF-XA7w0cg0iHtB3cSmF0","authorship_tag":"ABX9TyN5fLY8/XaVgAk/wQ0ixHoe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"34eb760a38dc4e459bd5a36a1af851d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0966feb31144591a939572e888fda46","IPY_MODEL_7a635d98e8ff4137abd8804ba07899dd","IPY_MODEL_014093f60be54669a1d6cb7facf34284"],"layout":"IPY_MODEL_8cc2fbacbb8e473f869539de55f5bf5e"}},"b0966feb31144591a939572e888fda46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de06b6add83841e2a6e47f909a431fe0","placeholder":"​","style":"IPY_MODEL_e3663bde069e4cca832fdeecb379d69e","value":"model.safetensors.index.json: 100%"}},"7a635d98e8ff4137abd8804ba07899dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e84b1297685049e08cfbe36b61ad00ff","max":375214,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10b42a20a7ab43a9a90c0f87198cce1b","value":375214}},"014093f60be54669a1d6cb7facf34284":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dae431b4f724401087d5d0dd9c7e126c","placeholder":"​","style":"IPY_MODEL_9f1a548bbb834e8f9f820efce716637c","value":" 375k/375k [00:00&lt;00:00, 4.36MB/s]"}},"8cc2fbacbb8e473f869539de55f5bf5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de06b6add83841e2a6e47f909a431fe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3663bde069e4cca832fdeecb379d69e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e84b1297685049e08cfbe36b61ad00ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10b42a20a7ab43a9a90c0f87198cce1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dae431b4f724401087d5d0dd9c7e126c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f1a548bbb834e8f9f820efce716637c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8793590e437d44829d08d1e64d40a4ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f11c0cd847174bce8fce3b174ba33d5b","IPY_MODEL_fd6af56769c5468b84b71b4f4728d698","IPY_MODEL_8a24c3c7c84245e58d6ab88daa018c8d"],"layout":"IPY_MODEL_9a8a177bb02d44f7b449f3799e424053"}},"f11c0cd847174bce8fce3b174ba33d5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10d83e1ebe0045f2b1fb55aec4e692f2","placeholder":"​","style":"IPY_MODEL_578d497e057e45ed97d1e2fcbf5123df","value":"Downloading shards: 100%"}},"fd6af56769c5468b84b71b4f4728d698":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27de5fde4a514b609f80f1dd8ebc1c5f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1daa591416be433fb19005649e9a85b9","value":2}},"8a24c3c7c84245e58d6ab88daa018c8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cee5ee5d6ede4928a74a0357bb1703cd","placeholder":"​","style":"IPY_MODEL_a8b5357ba8cd4efa86640e68c49e4aee","value":" 2/2 [01:12&lt;00:00, 33.24s/it]"}},"9a8a177bb02d44f7b449f3799e424053":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10d83e1ebe0045f2b1fb55aec4e692f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"578d497e057e45ed97d1e2fcbf5123df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27de5fde4a514b609f80f1dd8ebc1c5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1daa591416be433fb19005649e9a85b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cee5ee5d6ede4928a74a0357bb1703cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8b5357ba8cd4efa86640e68c49e4aee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c14faff223564430ac17cab900a0337b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc1a658a47154189b22f95241ea87cba","IPY_MODEL_aac52a26ce264f0083362e37eed5b314","IPY_MODEL_abcf69ae173c4b6dbcf75a2bb88dc901"],"layout":"IPY_MODEL_c392983b33eb452cad0722d87e3f79b4"}},"dc1a658a47154189b22f95241ea87cba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d16b44b7daf40daade62f61b4ac73c0","placeholder":"​","style":"IPY_MODEL_af123449534b4af6bc923fa4319b41eb","value":"model-00001-of-00002.safetensors: 100%"}},"aac52a26ce264f0083362e37eed5b314":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac511931a1d847159e882b2b37f3a564","max":4971535505,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a862d8c3d0404790ae065795184e143f","value":4971535031}},"abcf69ae173c4b6dbcf75a2bb88dc901":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21846f08ae614aee8dc4d1314affabbf","placeholder":"​","style":"IPY_MODEL_7c332f74cf364e1b9ba2e1c47534960b","value":" 4.97G/4.97G [00:51&lt;00:00, 331MB/s]"}},"c392983b33eb452cad0722d87e3f79b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d16b44b7daf40daade62f61b4ac73c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af123449534b4af6bc923fa4319b41eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac511931a1d847159e882b2b37f3a564":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a862d8c3d0404790ae065795184e143f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21846f08ae614aee8dc4d1314affabbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c332f74cf364e1b9ba2e1c47534960b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0129be2794a044ab8518bbc877a060c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b73eff04b163455b8511eadfa24ecd0c","IPY_MODEL_5a41a797ce6c41549b8a56c80059197e","IPY_MODEL_6a178f4513444c57a641d51841ae6894"],"layout":"IPY_MODEL_667405e3e67a41bbb60f269025abd1ef"}},"b73eff04b163455b8511eadfa24ecd0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa28e4e992c14d2b92b217949da9800d","placeholder":"​","style":"IPY_MODEL_430baa1a0a5b4de8b0d9a65122882d3b","value":"model-00002-of-00002.safetensors: 100%"}},"5a41a797ce6c41549b8a56c80059197e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c9a9cbb58664f6b934760fa7523b7b8","max":2937067316,"min":0,"orientation":"horizontal","style":"IPY_MODEL_293d43d176794d6eb0ebf146291ca169","value":2937067036}},"6a178f4513444c57a641d51841ae6894":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7465ea7c38e4ef89e2840209416773f","placeholder":"​","style":"IPY_MODEL_74fc3e3519ce4595bf6db68d98cb9cd3","value":" 2.94G/2.94G [00:19&lt;00:00, 311MB/s]"}},"667405e3e67a41bbb60f269025abd1ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa28e4e992c14d2b92b217949da9800d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"430baa1a0a5b4de8b0d9a65122882d3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c9a9cbb58664f6b934760fa7523b7b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"293d43d176794d6eb0ebf146291ca169":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7465ea7c38e4ef89e2840209416773f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74fc3e3519ce4595bf6db68d98cb9cd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cb1e0e1937d4aa2945f24e857a0a3a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_091f6c18b9fa46a0a24818f2278c46e4","IPY_MODEL_5d329195391b47758ce5c1128357f7a9","IPY_MODEL_4c1fde95ba144252b1f20b9367375454"],"layout":"IPY_MODEL_08fb486f20d74327a78ba6bae9110df6"}},"091f6c18b9fa46a0a24818f2278c46e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_978472b2e98642bbbb75a9f5f5bfd04d","placeholder":"​","style":"IPY_MODEL_a2b36d79456c4c83a276c77049dc388d","value":"Loading checkpoint shards: 100%"}},"5d329195391b47758ce5c1128357f7a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_94af7de58f7442cca012fe2ca3f877ca","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b412490a76447fcb824fcd0bac5a25b","value":2}},"4c1fde95ba144252b1f20b9367375454":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf62feb143844493827b28bf9ae0f936","placeholder":"​","style":"IPY_MODEL_50f5b4dcf5ff4bf7bb4c50d634dc1608","value":" 2/2 [00:38&lt;00:00, 18.24s/it]"}},"08fb486f20d74327a78ba6bae9110df6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"978472b2e98642bbbb75a9f5f5bfd04d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2b36d79456c4c83a276c77049dc388d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94af7de58f7442cca012fe2ca3f877ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b412490a76447fcb824fcd0bac5a25b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf62feb143844493827b28bf9ae0f936":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50f5b4dcf5ff4bf7bb4c50d634dc1608":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abac7c94aa454726a9ac0ce4570a2dd2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6cf3b9ba8dd1441bb49252bbfe6d930a","IPY_MODEL_fbed6587ea9e42f4aeda6219d35edd93","IPY_MODEL_afd37f9d5e50420aae4e7ed88d82e609"],"layout":"IPY_MODEL_23d59fa19aec46229f388512a30d0ff9"}},"6cf3b9ba8dd1441bb49252bbfe6d930a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75eed594dc7848b5805adbd208fbe3d4","placeholder":"​","style":"IPY_MODEL_637c73ac2a3744ec810117da7ef3a64b","value":"generation_config.json: 100%"}},"fbed6587ea9e42f4aeda6219d35edd93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e54205a1ca6c4405a93c1bcbc072bfe6","max":210,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbd2deb74d60451ca80b73cf101cfe4c","value":210}},"afd37f9d5e50420aae4e7ed88d82e609":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_330015b7db864621a925c7eb25ff77c4","placeholder":"​","style":"IPY_MODEL_873a5666db4e486880ca225e72ecd379","value":" 210/210 [00:00&lt;00:00, 12.1kB/s]"}},"23d59fa19aec46229f388512a30d0ff9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75eed594dc7848b5805adbd208fbe3d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"637c73ac2a3744ec810117da7ef3a64b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e54205a1ca6c4405a93c1bcbc072bfe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbd2deb74d60451ca80b73cf101cfe4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"330015b7db864621a925c7eb25ff77c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"873a5666db4e486880ca225e72ecd379":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5c0e7970cbe4ba18d504e038c1c17b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b278b26ad7964778bf89e29b99a36c6a","IPY_MODEL_fc96ca9dbf7e4addb9d8647563215e9d","IPY_MODEL_50af330643b24316b923d5f75630c943"],"layout":"IPY_MODEL_4f15a72a7f404ca889d724fcefe8bd77"}},"b278b26ad7964778bf89e29b99a36c6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bde3c5a510440549769e7040238832b","placeholder":"​","style":"IPY_MODEL_ef2f52b6baff483794a895146869fbd3","value":"preprocessor_config.json: 100%"}},"fc96ca9dbf7e4addb9d8647563215e9d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af393347adef4d5880393888bba16c38","max":477,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b60085b47a4340cbb1596d6ddeba0d61","value":477}},"50af330643b24316b923d5f75630c943":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af64df136a81452c8cdb3d5bcfce4323","placeholder":"​","style":"IPY_MODEL_912a8f2bf0f742cb96d81e2573ec3e09","value":" 477/477 [00:00&lt;00:00, 42.0kB/s]"}},"4f15a72a7f404ca889d724fcefe8bd77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bde3c5a510440549769e7040238832b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef2f52b6baff483794a895146869fbd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af393347adef4d5880393888bba16c38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b60085b47a4340cbb1596d6ddeba0d61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af64df136a81452c8cdb3d5bcfce4323":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"912a8f2bf0f742cb96d81e2573ec3e09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e978bfc04b24d519a0da7317eca8e7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c0e8ea9bfc749979f8079253008b570","IPY_MODEL_f101a83ba2334c44977ad8325efa4628","IPY_MODEL_1108a30f65f64c20afbcffeab1d79cf7"],"layout":"IPY_MODEL_de4c164f9f724ccdb2b13b8c3d9904cf"}},"5c0e8ea9bfc749979f8079253008b570":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46d2348f1ecc445baee9196fae1a3a62","placeholder":"​","style":"IPY_MODEL_a8516fefd6234648823ad69df4065d87","value":"tokenizer_config.json: 100%"}},"f101a83ba2334c44977ad8325efa4628":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59ff7bf922f04af1a975365ca9f09324","max":55931,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d32961ee38947cb86b3aae048da4b66","value":55931}},"1108a30f65f64c20afbcffeab1d79cf7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_110b2ff71b3c4544970a354dc49d91c2","placeholder":"​","style":"IPY_MODEL_57026395c5b94bdd9c890f5365e8499a","value":" 55.9k/55.9k [00:00&lt;00:00, 3.23MB/s]"}},"de4c164f9f724ccdb2b13b8c3d9904cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46d2348f1ecc445baee9196fae1a3a62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8516fefd6234648823ad69df4065d87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59ff7bf922f04af1a975365ca9f09324":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d32961ee38947cb86b3aae048da4b66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"110b2ff71b3c4544970a354dc49d91c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57026395c5b94bdd9c890f5365e8499a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f31c79cf2dc495c8f617c275b505dd3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b9f7a2a5a9b4337890be895ab4c35ff","IPY_MODEL_185e4157985b46a6a41997c3cbe92eab","IPY_MODEL_7b02a1c88c5b44bd87a5408959a0756b"],"layout":"IPY_MODEL_99af452baef04556a1f5a343f3cf173c"}},"3b9f7a2a5a9b4337890be895ab4c35ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01f4b172226440d1b14b04273014df12","placeholder":"​","style":"IPY_MODEL_daaf88ad06ac4d70bb45afdae12c4456","value":"tokenizer.json: 100%"}},"185e4157985b46a6a41997c3cbe92eab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c3a1b7fac08410a8ae123d4f64cf968","max":17210088,"min":0,"orientation":"horizontal","style":"IPY_MODEL_497b7c79560a485bb1f1b129f0a79a8b","value":17210088}},"7b02a1c88c5b44bd87a5408959a0756b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f94f044821e74c65babf3afc166981a5","placeholder":"​","style":"IPY_MODEL_002ab87f405e414897bec461db39a17c","value":" 17.2M/17.2M [00:00&lt;00:00, 42.6MB/s]"}},"99af452baef04556a1f5a343f3cf173c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01f4b172226440d1b14b04273014df12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"daaf88ad06ac4d70bb45afdae12c4456":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c3a1b7fac08410a8ae123d4f64cf968":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"497b7c79560a485bb1f1b129f0a79a8b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f94f044821e74c65babf3afc166981a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"002ab87f405e414897bec461db39a17c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f34af24761f844929b580f8d5bb17d10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_588d0d3b1a9e44a28743b243e39a1422","IPY_MODEL_33a59163f66343d7834bc967462c3513","IPY_MODEL_82dd26ee287f435494cfd84705dd649d"],"layout":"IPY_MODEL_a149c9e6ecb841c499885105b134efaf"}},"588d0d3b1a9e44a28743b243e39a1422":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bb15ff62fd644ce95bc373a9c274288","placeholder":"​","style":"IPY_MODEL_9b2063d9870541c3a25c0dad3a192e95","value":"special_tokens_map.json: 100%"}},"33a59163f66343d7834bc967462c3513":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be68c4f77a8c481182179ad668b8e158","max":454,"min":0,"orientation":"horizontal","style":"IPY_MODEL_929ddfb8daa5437c8d98807e43a8ccf6","value":454}},"82dd26ee287f435494cfd84705dd649d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e907cbcb9de24802b44d95329cd2485a","placeholder":"​","style":"IPY_MODEL_906d1d391fca485f8193ba72b1f5ff2d","value":" 454/454 [00:00&lt;00:00, 36.8kB/s]"}},"a149c9e6ecb841c499885105b134efaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bb15ff62fd644ce95bc373a9c274288":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b2063d9870541c3a25c0dad3a192e95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be68c4f77a8c481182179ad668b8e158":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"929ddfb8daa5437c8d98807e43a8ccf6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e907cbcb9de24802b44d95329cd2485a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"906d1d391fca485f8193ba72b1f5ff2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8400d039fed041c78b1306ef9a598858":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b7b81b5f5b34796910fef41f72fd0f6","IPY_MODEL_bcab31e72d5f47c686bd00ed3b08d9f0","IPY_MODEL_e313951b477f45fd91f6048c8cbcaf25"],"layout":"IPY_MODEL_61ed5c19512e4279b377c064b87e3cfe"}},"1b7b81b5f5b34796910fef41f72fd0f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e070b20b3004259818d01afb6c7d23a","placeholder":"​","style":"IPY_MODEL_6e6ca62c4ac543d4b514e099bc178080","value":"chat_template.json: 100%"}},"bcab31e72d5f47c686bd00ed3b08d9f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_950c4126aaa34cf1a1b06e75b4859bdf","max":5151,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45e2669c12ab49388dea2bcb266cc2eb","value":5151}},"e313951b477f45fd91f6048c8cbcaf25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0e61c45030b467bb275e2a1dd16970b","placeholder":"​","style":"IPY_MODEL_eeda551b55a24773a0ea3b306dd214c9","value":" 5.15k/5.15k [00:00&lt;00:00, 467kB/s]"}},"61ed5c19512e4279b377c064b87e3cfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e070b20b3004259818d01afb6c7d23a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e6ca62c4ac543d4b514e099bc178080":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"950c4126aaa34cf1a1b06e75b4859bdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45e2669c12ab49388dea2bcb266cc2eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0e61c45030b467bb275e2a1dd16970b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eeda551b55a24773a0ea3b306dd214c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"954d7f0cbcd44448af8e855f36f8bb9e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1fb470fdd818410aab38d26ee3c6e3b2","IPY_MODEL_a22119008fea45f5a1b844fc9e3cda36","IPY_MODEL_d3386c6fae3f44f9a8110bf732f8c85b"],"layout":"IPY_MODEL_d413635fc64948faae62df9471e50272"}},"1fb470fdd818410aab38d26ee3c6e3b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_559b48eac53b49e8a765d6d3fcb8f0be","placeholder":"​","style":"IPY_MODEL_144fd5fb8e444e569dc6adc6ffcdc614","value":"adapter_model.safetensors: 100%"}},"a22119008fea45f5a1b844fc9e3cda36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c4b1b074d4043da934949ddffbcabd1","max":268855232,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e238ec2a343c466d89b375293ff0fa10","value":268855207}},"d3386c6fae3f44f9a8110bf732f8c85b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9c8fd6eb4394e34b751e97eefdad545","placeholder":"​","style":"IPY_MODEL_a761ae2b00ae4b60b5415059ac46bc36","value":" 269M/269M [00:02&lt;00:00, 184MB/s]"}},"d413635fc64948faae62df9471e50272":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"559b48eac53b49e8a765d6d3fcb8f0be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"144fd5fb8e444e569dc6adc6ffcdc614":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c4b1b074d4043da934949ddffbcabd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e238ec2a343c466d89b375293ff0fa10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9c8fd6eb4394e34b751e97eefdad545":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a761ae2b00ae4b60b5415059ac46bc36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# Import libraries\n","import numpy as np\n","import os\n","from PIL import Image\n","import random\n","\n","# Set random seed\n","random.seed(42)\n","\n","# Unload all data such that it's easily accessible\n","main_data_path = \"/content/drive/MyDrive/ENGSCI/4TH YEAR/fall 4th year/ESC499/Code Test/Finetuning/Data/\"\n","training_data_path = main_data_path+\"training\"\n","test_data_path = main_data_path+\"test\"\n","training_seg_path = main_data_path+\"train_seg_bbounds.npz\"\n","test_seg_path = main_data_path+\"test_seg_bbounds.npz\""],"metadata":{"id":"twDSWNOuFHSt","executionInfo":{"status":"ok","timestamp":1739401724933,"user_tz":300,"elapsed":226,"user":{"displayName":"Felicia Liu","userId":"08082401212792009907"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# 42s 44s\n","%%capture\n","!pip install unsloth\n","# Also get the latest nightly Unsloth!\n","!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n"],"metadata":{"id":"lrHhJrZvFIuV","executionInfo":{"status":"ok","timestamp":1739401944083,"user_tz":300,"elapsed":216846,"user":{"displayName":"Felicia Liu","userId":"08082401212792009907"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_eCDYVlk6swk","executionInfo":{"status":"ok","timestamp":1739401995070,"user_tz":300,"elapsed":37056,"user":{"displayName":"Felicia Liu","userId":"08082401212792009907"}},"outputId":"59b08d1a-c065-4a5f-e7f3-cdca143ddc6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Collecting torchaudio\n","  Downloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torchaudio\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.5.1+cu124\n","    Uninstalling torchaudio-2.5.1+cu124:\n","      Successfully uninstalled torchaudio-2.5.1+cu124\n","Successfully installed torchaudio-2.6.0\n","🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n"]}],"source":["!pip install --upgrade torch torchvision torchaudio # Upgrading PyTorch to the latest version\n","import torchvision\n","from unsloth import FastVisionModel # FastLanguageModel for LLMs\n","import torch\n","from unsloth import is_bf16_supported\n","from unsloth.trainer import UnslothVisionDataCollator\n","from trl import SFTTrainer, SFTConfig\n","from transformers import TextStreamer\n","from transformers import TrainerCallback, TrainingArguments"]},{"cell_type":"code","source":["# Mount the Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJGjNNso8yvd","executionInfo":{"status":"ok","timestamp":1739402014825,"user_tz":300,"elapsed":17440,"user":{"displayName":"Felicia Liu","userId":"08082401212792009907"}},"outputId":"a07f7a90-13ec-4d50-d7da-b0e8a66a9156"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Functions (TEST VERSION)\n","\n","def load_scan_from_npz(file_path):\n","    data = np.load(file_path)\n","    return data['voxel'], data['ax'], data['sag'], data['cor'], data['label']\n","\n","def pair_segs(filename, patient_specific_bb):\n","    v, a, s, c, l = load_scan_from_npz(filename)\n","    begin, end = a\n","    image_seg_pairs = []\n","    for i in range(begin+20, end+1-20, 1):\n","        row_min, col_min, row_max, col_max = patient_specific_bb[i]\n","        np_array, label = v[i], l\n","        np_array = np.uint8(255 * (np_array - np.min(np_array)) / (np.max(np_array) - np.min(np_array)))\n","        image = Image.fromarray(np_array)\n","        image_seg_pairs.append({\"image\":image, \"bb\":[(row_min, col_min), (row_min, col_max), (row_max, col_max), (row_max, col_min)] })\n","    return image_seg_pairs\n","\n","def load_normal_npz(file_path):\n","    loaded_data = np.load(file_path)\n","    return loaded_data['array']\n","\n","\n","def convert_to_conversation(sample):\n","    instruction = '''\n","You are an expert medical AI assistant specializing in glioma segmentation on FLAIR-mode brain scans.\n","Given a 128x128 grayscale brain scan, output the bounding box around the tumor using the four corner vertices.\n","The tumor region is the brightest, high-intensity abnormality distinct from normal brain structures.\n","Ensure the bounding box tightly encloses the entire tumor without extending into non-tumor regions.\n","The bounding box output must be formatted strictly as:[(row_min, col_min), (row_min, col_max), (row_max, col_max), (row_max, col_min)] where (row, col) are integers between 0 and 127, with (0,0) at the top-left and row increasing downward, and col increasing rightward.\n","Do not output any other text or explanation, only the coordinate list in the exact format above.\n","    '''\n","\n","    conversation = [\n","        { \"role\": \"user\",\n","          \"content\" : [\n","            {\"type\" : \"text\",  \"text\"  : instruction},\n","            {\"type\" : \"image\", \"image\" : sample['image']} ]\n","        },\n","        { \"role\" : \"assistant\",\n","          \"content\" : [\n","            {\"type\": \"text\", \"text\": f\"{sample['bb']}\"} ]\n","        },\n","    ]\n","    return { \"messages\" : conversation }\n","\n","\n","def create_conversation_dataset(data_path, segs_path):\n","\n","    segs_bb = load_normal_npz(segs_path)\n","\n","    # Extract all the patients and the corresponding filenames\n","    filenames = []\n","    for filename in os.listdir(data_path):\n","        if filename.endswith(\".npz\"):\n","            file_path = os.path.join(data_path, filename)\n","            filenames.append(file_path)\n","    filenames = sorted(filenames, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n","\n","    # Now we build the dataset\n","    patients = []\n","    for index in range(len(filenames)):\n","        filename = filenames[index]\n","        patient_specific_bb = segs_bb[index]\n","        image_seg_pairs = pair_segs(filename, patient_specific_bb)\n","        patients.append(image_seg_pairs)\n","        # patients += image_seg_pairs\n","\n","    # Now convert the dataset into input for LLM\n","    llm_patients = []\n","    for patient in patients:\n","        llm_patient = [convert_to_conversation(sample) for sample in patient]\n","        llm_patients.append(llm_patient)\n","    print(f\"Number of patients: {len(llm_patients)}\")\n","    print(llm_patients[0][0])\n","\n","    return patients, llm_patients\n"],"metadata":{"id":"1tbAA4WQ60Ws","executionInfo":{"status":"ok","timestamp":1739402038909,"user_tz":300,"elapsed":131,"user":{"displayName":"Felicia Liu","userId":"08082401212792009907"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["data_patients, llm_patients = create_conversation_dataset(test_data_path, test_seg_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMCfXh2TcNSM","executionInfo":{"status":"ok","timestamp":1739402110014,"user_tz":300,"elapsed":66489,"user":{"displayName":"Felicia Liu","userId":"08082401212792009907"}},"outputId":"5232e399-bd78-42ae-aaf1-d604bca40597"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of patients: 55\n","{'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': '\\nYou are an expert medical AI assistant specializing in glioma segmentation on FLAIR-mode brain scans.\\nGiven a 128x128 grayscale brain scan, output the bounding box around the tumor using the four corner vertices.\\nThe tumor region is the brightest, high-intensity abnormality distinct from normal brain structures.\\nEnsure the bounding box tightly encloses the entire tumor without extending into non-tumor regions.\\nThe bounding box output must be formatted strictly as:[(row_min, col_min), (row_min, col_max), (row_max, col_max), (row_max, col_min)] where (row, col) are integers between 0 and 127, with (0,0) at the top-left and row increasing downward, and col increasing rightward.\\nDo not output any other text or explanation, only the coordinate list in the exact format above.\\n    '}, {'type': 'image', 'image': <PIL.Image.Image image mode=L size=128x128 at 0x7B24BF51A290>}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': '[(20, 75), (20, 126), (76, 126), (76, 75)]'}]}]}\n"]}]},{"cell_type":"code","source":["# Add the name of the model we want to import\n","# lora_model_name = \"liufelic/seg_100step_model\"\n","lora_model_name = \"liufelic/seg_200step_model\"\n","\n","# Load the model we previously trained\n","from unsloth import FastVisionModel\n","model, tokenizer = FastVisionModel.from_pretrained(\n","    model_name = lora_model_name, # YOUR MODEL YOU USED FOR TRAINING\n","    load_in_4bit = True, # Set to False for 16bit LoRA\n",")\n","FastVisionModel.for_inference(model) # Enable for inference!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["34eb760a38dc4e459bd5a36a1af851d1","b0966feb31144591a939572e888fda46","7a635d98e8ff4137abd8804ba07899dd","014093f60be54669a1d6cb7facf34284","8cc2fbacbb8e473f869539de55f5bf5e","de06b6add83841e2a6e47f909a431fe0","e3663bde069e4cca832fdeecb379d69e","e84b1297685049e08cfbe36b61ad00ff","10b42a20a7ab43a9a90c0f87198cce1b","dae431b4f724401087d5d0dd9c7e126c","9f1a548bbb834e8f9f820efce716637c","8793590e437d44829d08d1e64d40a4ea","f11c0cd847174bce8fce3b174ba33d5b","fd6af56769c5468b84b71b4f4728d698","8a24c3c7c84245e58d6ab88daa018c8d","9a8a177bb02d44f7b449f3799e424053","10d83e1ebe0045f2b1fb55aec4e692f2","578d497e057e45ed97d1e2fcbf5123df","27de5fde4a514b609f80f1dd8ebc1c5f","1daa591416be433fb19005649e9a85b9","cee5ee5d6ede4928a74a0357bb1703cd","a8b5357ba8cd4efa86640e68c49e4aee","c14faff223564430ac17cab900a0337b","dc1a658a47154189b22f95241ea87cba","aac52a26ce264f0083362e37eed5b314","abcf69ae173c4b6dbcf75a2bb88dc901","c392983b33eb452cad0722d87e3f79b4","5d16b44b7daf40daade62f61b4ac73c0","af123449534b4af6bc923fa4319b41eb","ac511931a1d847159e882b2b37f3a564","a862d8c3d0404790ae065795184e143f","21846f08ae614aee8dc4d1314affabbf","7c332f74cf364e1b9ba2e1c47534960b","0129be2794a044ab8518bbc877a060c1","b73eff04b163455b8511eadfa24ecd0c","5a41a797ce6c41549b8a56c80059197e","6a178f4513444c57a641d51841ae6894","667405e3e67a41bbb60f269025abd1ef","aa28e4e992c14d2b92b217949da9800d","430baa1a0a5b4de8b0d9a65122882d3b","8c9a9cbb58664f6b934760fa7523b7b8","293d43d176794d6eb0ebf146291ca169","d7465ea7c38e4ef89e2840209416773f","74fc3e3519ce4595bf6db68d98cb9cd3","2cb1e0e1937d4aa2945f24e857a0a3a4","091f6c18b9fa46a0a24818f2278c46e4","5d329195391b47758ce5c1128357f7a9","4c1fde95ba144252b1f20b9367375454","08fb486f20d74327a78ba6bae9110df6","978472b2e98642bbbb75a9f5f5bfd04d","a2b36d79456c4c83a276c77049dc388d","94af7de58f7442cca012fe2ca3f877ca","6b412490a76447fcb824fcd0bac5a25b","cf62feb143844493827b28bf9ae0f936","50f5b4dcf5ff4bf7bb4c50d634dc1608","abac7c94aa454726a9ac0ce4570a2dd2","6cf3b9ba8dd1441bb49252bbfe6d930a","fbed6587ea9e42f4aeda6219d35edd93","afd37f9d5e50420aae4e7ed88d82e609","23d59fa19aec46229f388512a30d0ff9","75eed594dc7848b5805adbd208fbe3d4","637c73ac2a3744ec810117da7ef3a64b","e54205a1ca6c4405a93c1bcbc072bfe6","fbd2deb74d60451ca80b73cf101cfe4c","330015b7db864621a925c7eb25ff77c4","873a5666db4e486880ca225e72ecd379","e5c0e7970cbe4ba18d504e038c1c17b1","b278b26ad7964778bf89e29b99a36c6a","fc96ca9dbf7e4addb9d8647563215e9d","50af330643b24316b923d5f75630c943","4f15a72a7f404ca889d724fcefe8bd77","2bde3c5a510440549769e7040238832b","ef2f52b6baff483794a895146869fbd3","af393347adef4d5880393888bba16c38","b60085b47a4340cbb1596d6ddeba0d61","af64df136a81452c8cdb3d5bcfce4323","912a8f2bf0f742cb96d81e2573ec3e09","9e978bfc04b24d519a0da7317eca8e7d","5c0e8ea9bfc749979f8079253008b570","f101a83ba2334c44977ad8325efa4628","1108a30f65f64c20afbcffeab1d79cf7","de4c164f9f724ccdb2b13b8c3d9904cf","46d2348f1ecc445baee9196fae1a3a62","a8516fefd6234648823ad69df4065d87","59ff7bf922f04af1a975365ca9f09324","7d32961ee38947cb86b3aae048da4b66","110b2ff71b3c4544970a354dc49d91c2","57026395c5b94bdd9c890f5365e8499a","3f31c79cf2dc495c8f617c275b505dd3","3b9f7a2a5a9b4337890be895ab4c35ff","185e4157985b46a6a41997c3cbe92eab","7b02a1c88c5b44bd87a5408959a0756b","99af452baef04556a1f5a343f3cf173c","01f4b172226440d1b14b04273014df12","daaf88ad06ac4d70bb45afdae12c4456","5c3a1b7fac08410a8ae123d4f64cf968","497b7c79560a485bb1f1b129f0a79a8b","f94f044821e74c65babf3afc166981a5","002ab87f405e414897bec461db39a17c","f34af24761f844929b580f8d5bb17d10","588d0d3b1a9e44a28743b243e39a1422","33a59163f66343d7834bc967462c3513","82dd26ee287f435494cfd84705dd649d","a149c9e6ecb841c499885105b134efaf","6bb15ff62fd644ce95bc373a9c274288","9b2063d9870541c3a25c0dad3a192e95","be68c4f77a8c481182179ad668b8e158","929ddfb8daa5437c8d98807e43a8ccf6","e907cbcb9de24802b44d95329cd2485a","906d1d391fca485f8193ba72b1f5ff2d","8400d039fed041c78b1306ef9a598858","1b7b81b5f5b34796910fef41f72fd0f6","bcab31e72d5f47c686bd00ed3b08d9f0","e313951b477f45fd91f6048c8cbcaf25","61ed5c19512e4279b377c064b87e3cfe","4e070b20b3004259818d01afb6c7d23a","6e6ca62c4ac543d4b514e099bc178080","950c4126aaa34cf1a1b06e75b4859bdf","45e2669c12ab49388dea2bcb266cc2eb","f0e61c45030b467bb275e2a1dd16970b","eeda551b55a24773a0ea3b306dd214c9","954d7f0cbcd44448af8e855f36f8bb9e","1fb470fdd818410aab38d26ee3c6e3b2","a22119008fea45f5a1b844fc9e3cda36","d3386c6fae3f44f9a8110bf732f8c85b","d413635fc64948faae62df9471e50272","559b48eac53b49e8a765d6d3fcb8f0be","144fd5fb8e444e569dc6adc6ffcdc614","7c4b1b074d4043da934949ddffbcabd1","e238ec2a343c466d89b375293ff0fa10","b9c8fd6eb4394e34b751e97eefdad545","a761ae2b00ae4b60b5415059ac46bc36"]},"collapsed":true,"id":"bFuecXor60dq","executionInfo":{"status":"ok","timestamp":1739402297186,"user_tz":300,"elapsed":134859,"user":{"displayName":"Felicia Liu","userId":"08082401212792009907"}},"outputId":"ae3e212d-8d34-496c-f605-63b02b66161d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.2.4: Fast Mllama vision patching. Transformers: 4.48.2.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/375k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34eb760a38dc4e459bd5a36a1af851d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8793590e437d44829d08d1e64d40a4ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c14faff223564430ac17cab900a0337b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/2.94G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0129be2794a044ab8518bbc877a060c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cb1e0e1937d4aa2945f24e857a0a3a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abac7c94aa454726a9ac0ce4570a2dd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/477 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5c0e7970cbe4ba18d504e038c1c17b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/55.9k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e978bfc04b24d519a0da7317eca8e7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f31c79cf2dc495c8f617c275b505dd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f34af24761f844929b580f8d5bb17d10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["chat_template.json:   0%|          | 0.00/5.15k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8400d039fed041c78b1306ef9a598858"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["adapter_model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954d7f0cbcd44448af8e855f36f8bb9e"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): MllamaForConditionalGeneration(\n","      (vision_model): MllamaVisionModel(\n","        (patch_embedding): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14), padding=valid, bias=False)\n","        (gated_positional_embedding): MllamaPrecomputedPositionEmbedding(\n","          (tile_embedding): Embedding(9, 8197120)\n","        )\n","        (pre_tile_positional_embedding): MllamaPrecomputedAspectRatioEmbedding(\n","          (embedding): Embedding(9, 5120)\n","        )\n","        (post_tile_positional_embedding): MllamaPrecomputedAspectRatioEmbedding(\n","          (embedding): Embedding(9, 5120)\n","        )\n","        (layernorm_pre): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (layernorm_post): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (transformer): MllamaVisionEncoder(\n","          (layers): ModuleList(\n","            (0-12): 13 x MllamaVisionEncoderLayer(\n","              (self_attn): MllamaVisionSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaVisionMLP(\n","                (activation_fn): GELUActivation()\n","                (fc1): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=5120, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (fc2): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=5120, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (input_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","              (post_attention_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (13): MllamaVisionEncoderLayer(\n","              (self_attn): MllamaVisionSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaVisionMLP(\n","                (activation_fn): GELUActivation()\n","                (fc1): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=5120, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (fc2): lora.Linear(\n","                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=5120, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (input_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","              (post_attention_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (14-31): 18 x MllamaVisionEncoderLayer(\n","              (self_attn): MllamaVisionSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaVisionMLP(\n","                (activation_fn): GELUActivation()\n","                (fc1): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=5120, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (fc2): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=5120, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (input_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","              (post_attention_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","        )\n","        (global_transformer): MllamaVisionEncoder(\n","          (layers): ModuleList(\n","            (0-7): 8 x MllamaVisionEncoderLayer(\n","              (self_attn): MllamaVisionSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaVisionMLP(\n","                (activation_fn): GELUActivation()\n","                (fc1): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=5120, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (fc2): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=5120, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (input_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","              (post_attention_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","        )\n","      )\n","      (language_model): MllamaForCausalLM(\n","        (model): MllamaTextModel(\n","          (embed_tokens): Embedding(128264, 4096, padding_idx=128004)\n","          (layers): ModuleList(\n","            (0): MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (1): MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (2): MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (3): MllamaCrossAttentionDecoderLayer(\n","              (cross_attn): MllamaTextCrossSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (4-7): 4 x MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (8): MllamaCrossAttentionDecoderLayer(\n","              (cross_attn): MllamaTextCrossSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (9-12): 4 x MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (13): MllamaCrossAttentionDecoderLayer(\n","              (cross_attn): MllamaTextCrossSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (14-17): 4 x MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (18): MllamaCrossAttentionDecoderLayer(\n","              (cross_attn): MllamaTextCrossSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (19-22): 4 x MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (23): MllamaCrossAttentionDecoderLayer(\n","              (cross_attn): MllamaTextCrossSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (24-27): 4 x MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (28): MllamaCrossAttentionDecoderLayer(\n","              (cross_attn): MllamaTextCrossSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (29-32): 4 x MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (33): MllamaCrossAttentionDecoderLayer(\n","              (cross_attn): MllamaTextCrossSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (34-37): 4 x MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (38): MllamaCrossAttentionDecoderLayer(\n","              (cross_attn): MllamaTextCrossSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear(\n","                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","            (39): MllamaSelfAttentionDecoderLayer(\n","              (self_attn): MllamaTextSelfSdpaAttention(\n","                (q_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (k_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (v_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=1024, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (o_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","              )\n","              (mlp): MllamaTextMLP(\n","                (gate_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (up_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=4096, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=14336, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (down_proj): lora.Linear4bit(\n","                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Identity()\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=14336, out_features=16, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=16, out_features=4096, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                  (lora_magnitude_vector): ModuleDict()\n","                )\n","                (act_fn): SiLU()\n","              )\n","              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","            )\n","          )\n","          (norm): MllamaTextRMSNorm((4096,), eps=1e-05)\n","          (rotary_emb): MllamaRotaryEmbedding()\n","        )\n","        (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n","      )\n","      (multi_modal_projector): Linear(in_features=7680, out_features=4096, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import re\n","\n","def extract_choice(output_text):\n","    bbox_pattern = r\"\\[\\((\\d{1,3}, \\d{1,3})\\), \\((\\d{1,3}, \\d{1,3})\\), \\((\\d{1,3}, \\d{1,3})\\), \\((\\d{1,3}, \\d{1,3})\\)\\]\"\n","    match = re.search(bbox_pattern, output_text)\n","    if match: return match.group(0)\n","    else: return output_text.split(\"assistant\")[-1].strip()\n","\n","def write_file_for_one_patient(patient, path):\n","    # Open the file in append mode (if it doesn't exist, it will be created)\n","    with open(path, 'w') as file:\n","      for sample_id in range(len(patient)):\n","\n","          # Extract the info from the message\n","          sample = patient[sample_id]\n","          image = sample[\"image\"]\n","          ground_truth = sample[\"bb\"]\n","\n","          # Instruction\n","          instruction = '''\n","          You are an expert medical AI assistant specializing in glioma segmentation on FLAIR-mode brain scans.\n","          Given a 128x128 grayscale brain scan, output the bounding box around the tumor using the four corner vertices.\n","          The tumor region is the brightest, high-intensity abnormality distinct from normal brain structures.\n","          Ensure the bounding box tightly encloses the entire tumor without extending into non-tumor regions.\n","          The bounding box output must be formatted strictly as:[(row_min, col_min), (row_min, col_max), (row_max, col_max), (row_max, col_min)] where (row, col) are integers between 0 and 127, with (0,0) at the top-left and row increasing downward, and col increasing rightward.\n","          Do not output any other text or explanation, only the coordinate list in the exact format above.\n","          '''\n","          messages = [\n","              {\"role\": \"user\", \"content\": [\n","                  {\"type\": \"image\"},\n","                  {\"type\": \"text\", \"text\": instruction}\n","              ]}\n","          ]\n","\n","          input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n","          inputs = tokenizer(\n","              image,\n","              input_text,\n","              add_special_tokens=False,\n","              return_tensors=\"pt\",\n","          ).to(\"cuda\")\n","\n","          # Generate the tokens\n","          output_tokens = model.generate(**inputs, max_new_tokens=40,\n","                                          use_cache=True, temperature=1.5, min_p=0.1)\n","          generated_text = extract_choice(tokenizer.decode(output_tokens[0], skip_special_tokens=True))\n","\n","          # Prepare the output message\n","          result_message = f\"Ground truth: {ground_truth} || Model output: {generated_text}\"\n","\n","          # # Print to the terminal\n","          # print(result_message)\n","\n","          # Write to the file\n","          file.write(result_message + '\\n')  # Add a newline after each entry\n","\n","    return\n"],"metadata":{"id":"9tYBqHvq60gH","executionInfo":{"status":"ok","timestamp":1739403267721,"user_tz":300,"elapsed":152,"user":{"displayName":"Felicia Liu","userId":"08082401212792009907"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Unload all data such that it's easily accessible\n","main_results_folder = \"/content/drive/MyDrive/ENGSCI/4TH YEAR/fall 4th year/ESC499/Code Test/Finetuning/Results/\"\n","\n","# for patient_id in range(len(data_patients)):\n","for patient_id in range(55):\n","\n","    print(f\"Patient ID: {patient_id}\")\n","    patient = data_patients[patient_id]\n","\n","    # path for patient data storage\n","    patient_results_text = main_results_folder + f\"patient_{patient_id}.txt\"\n","    write_file_for_one_patient(patient, patient_results_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hoICtA8u60iW","executionInfo":{"status":"ok","timestamp":1739412110960,"user_tz":300,"elapsed":1048352,"user":{"displayName":"Felicia Liu","userId":"08082401212792009907"}},"outputId":"5ecdcd58-3df4-4401-8c9a-317ed62b9339"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Patient ID: 0\n","Patient ID: 1\n","Patient ID: 2\n","Patient ID: 3\n","Patient ID: 4\n","Patient ID: 5\n","Patient ID: 6\n","Patient ID: 7\n","Patient ID: 8\n","Patient ID: 9\n","Patient ID: 10\n","Patient ID: 11\n","Patient ID: 12\n","Patient ID: 13\n","Patient ID: 14\n","Patient ID: 15\n","Patient ID: 16\n","Patient ID: 17\n","Patient ID: 18\n","Patient ID: 19\n","Patient ID: 20\n","Patient ID: 21\n","Patient ID: 22\n","Patient ID: 23\n","Patient ID: 24\n","Patient ID: 25\n","Patient ID: 26\n","Patient ID: 27\n","Patient ID: 28\n","Patient ID: 29\n","Patient ID: 30\n","Patient ID: 31\n","Patient ID: 32\n","Patient ID: 33\n","Patient ID: 34\n","Patient ID: 35\n","Patient ID: 36\n","Patient ID: 37\n","Patient ID: 38\n","Patient ID: 39\n","Patient ID: 40\n","Patient ID: 41\n","Patient ID: 42\n","Patient ID: 43\n","Patient ID: 44\n","Patient ID: 45\n","Patient ID: 46\n","Patient ID: 47\n","Patient ID: 48\n","Patient ID: 49\n","Patient ID: 50\n","Patient ID: 51\n","Patient ID: 52\n","Patient ID: 53\n","Patient ID: 54\n"]}]}]}