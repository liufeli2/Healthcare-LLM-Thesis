# A comprehensive exploration and evaluation of foundational and subspecialized LLMs in healthcare and medicine

This repository contains the code and resources for my undergraduate thesis under Dr. Farzad Khalvati (IMICs Lab) and PhD Jay Yoo.: A Comprehensive Exploration and Evaluation of Foundational and Subspecialized Large Language Models in Healthcare and Medicine. The project investigates the performance of general-purpose and specialized LLMs in various healthcare tasks including image classification and segmentation, with a focus on assessing their accuracy, robustness, and utility.

**Author:** Felicia Liu 
~ *Engineering Science (Robotics Major) 2T4 + PEY*

**Current Project Description:**

![high_grade](Data-Processing/Sample-Images/HGG.gif)

> The motivation behind this research is to develop a more informed understanding of large language models (LLMs) and their capabilities in healthcare, an important yet under-explored area. The proposed thesis aims to comprehensively evaluate large language models (LLMs) trained on extensive medical datasets and compare them to specialized LLMs tailored for specific healthcare tasks, assessing the accuracy, robustness, and overall utility of LLMs across various medical applications. Many medical problems lack vast datasets to train LLMs with. Therefore, we aim to determine if specialized models, despite being trained on smaller, more niche datasets, can outperform generalized models in these focused areas. In addition, the proposed thesis will also evaluate the effectiveness of LLMs on medical tasks where LLMs would not commonly be used, such as image classification. The study will offer insight into how LLMs can be best applied to medical tasks that are rarely explored using LLMs. 